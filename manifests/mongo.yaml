id: mongo
name: Mongo
description: |
  Mongo integration
blocks:
  - title: Overview
    content: |+
      The integration with MongoDB substantially boosts the potential for data exploration and monitoring, providing a sleek and resilient tool for those seeking to uplift their data handling processes.
      ## Utilizing ODD Collector with Mongo
      To take full advantage of OpenDataDiscovery in conjunction with MongoDB, users should utilize the ODD Collector. 
      This specialized agent extracts metadata directly from MongoDB using its API, functioning as a central repository to store structural and operational metadata for all your data assets. 
      The ODD Collector employs a non-invasive method, ensuring there's no performance impact on your data infrastructure. MongoDB, a highly flexible and scalable document database, provides an API for this direct interaction. 
      This way, the ODD Collector can access and consolidate metadata from MongoDB's various data stores, and it remains compatible with popular data discovery applications.
  - title: Configure
    content: |+
      ## AWS Glue
      It is recommended to create a separate IAM user with the least privilege policy

      ## ODD Platform
      To integrate ODD Collector with the ODD Platform, users must first establish a collector entity within the platform by following these steps:

      1. Navigate to the "Management" section and select "Collectors".
      2. Click on the "Add Collector" button to initiate the process.
      3. Input a unique name for the collector and, optionally, provide a namespace to further categorize and organize the entity. Additionally, you may include a brief description to give more context and information about the collector.
      4. Click "Save" to finalize the setup, and take note of the generated token. This token will be required for incorporating it into the ODD Collector's configuration YAML file, ensuring secure communication between the two components.

      ## ODD Collector
      The process of configuring the ODD Collector involves creating and customizing a single, well-structured YAML configuration file

      ````yaml
      # ODD Platform's host URL
      platform_host_url: https://your.odd.platform

      # Default pulling interval in minutes, can be omit to run collector once
      default_pulling_interval: 10

      # Chunk size for ingestion, can be omit to use default value
      chunk_size: 1000

      # Collector's specific security token
      token: ""

      - type: redshift
        # Data source's name
        name: redshift_adapter
        # Optional Data source's description
        description: "Redshift sample database"
        # Redshift database to scrape
        database: "redhift_database"
        # Redshift host
        host: redshift-cluster.hostpart.awsregion.redshift.amazonaws.com
        # Redshift port
        port: 0000
        # Redshift credentials
        user: username
        password: password
        # Schemas to scrape. When ommited parse all schemas within databas (except system schemas)
        schemas: ['schema1', 'schema2']
        # Redshift Connection timeout
        connection_timeout: 10 
      ````
    snippets:
      - template: |+
          ````yaml
          platform_host_url: {{ platform_url }}
          default_pulling_interval: 10
          token: <Security token>
          plugins:
            - type: redshift
              name: {{ ds_name }}
              description: {{ plugin_description }}
              host: {{ redshift_host }}
              database: {{ redshift_database }}
              port: {{ redshift_port }}
              user: {{ redshift_user }}
              password:  <Password for {{ redshift_user }}>
              schemas: ['schema'] # Optional List[str], when ommitted parse all schemas (except system schemas)
              connection_timeout: 10
          ````
        arguments:
          - parameter: platform_url
            type: STRING
            static: true
          - parameter: ds_name
            name: Data source name
            type: STRING
          - parameter: plugin_description
            name: Data source description
            type: STRING
          - parameter: redshift_host
            name: Redshift host
            type: STRING
          - parameter: redshift_database
            name: Redshift database
            type: STRING
          - parameter: redshift_port
            name: Redshift port
            type: INTEGER
          - parameter: redshift_username
            name: Redshift username
            type: STRING